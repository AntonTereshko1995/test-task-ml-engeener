{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") \n",
    "\n",
    "from src.dataprep import transformations\n",
    "import pandas as pd\n",
    "from jobtools.arguments import ParamsNamespace\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/JobLevelData.xlsx\"\n",
    "params_file = \"../src/bert_classifier.params.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_excel(data_path)\n",
    "params = ParamsNamespace.load(params_file)\n",
    "feature_columns = params.data.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = transformations.remove_empty_rows(data_frame, \"Column 1\")\n",
    "data_frame = transformations.set_low_register(data_frame)\n",
    "data_frame.fillna(\"\", inplace=True)\n",
    "all_labels = set(data_frame[\"Column 1\"].tolist() + data_frame[\"Column 2\"].tolist() + data_frame[\"Column 3\"].tolist())\n",
    "# all_labels = transformations.combine_columns(data_frame, feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_labels.discard(\"\")  # Remove empty labels\n",
    "\n",
    "# Create a one-hot encoded label matrix\n",
    "def encode_labels(row):\n",
    "    return [1 if label in row.values else 0 for label in all_labels]\n",
    "\n",
    "data_frame[\"Features\"] = data_frame[[\"Column 1\", \"Column 2\", \"Column 3\", \"Column 4\"]].apply(encode_labels, axis=1)\n",
    "\n",
    "# Drop unnecessary columns (keeping Title and Labels)\n",
    "df = data_frame[[\"Title\", \"Features\"]]\n",
    "\n",
    "# Convert to list format\n",
    "train_texts = data_frame[\"Title\"].tolist()\n",
    "train_labels = data_frame[\"Features\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch dataset\n",
    "class JobDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32).to(device)  # Multi-label requires float32\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = self.labels[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df[\"Title\"].tolist()\n",
    "valid_texts = valid_df[\"Title\"].tolist()\n",
    "test_texts = test_df[\"Title\"].tolist()\n",
    "\n",
    "train_labels = train_df[\"Features\"].tolist()\n",
    "valid_labels = valid_df[\"Features\"].tolist()\n",
    "test_labels = test_df[\"Features\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_function(texts):\n",
    "    return tokenizer(texts, padding=\"max_length\", truncation=True, max_length=64)\n",
    "\n",
    "train_encodings = tokenize_function(train_texts)\n",
    "valid_encodings = tokenize_function(valid_texts)\n",
    "test_encodings = tokenize_function(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = JobDataset(train_encodings, train_labels)\n",
    "valid_dataset = JobDataset(valid_encodings, valid_labels)\n",
    "test_dataset = JobDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(all_labels)  # Number of classification categories\n",
    "\n",
    "# Load BERT model for multi-label classification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels, problem_type=\"multi_label_classification\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"no\",  # Disable evaluation\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=7,\n",
    "    weight_decay=0.05,\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    eval_dataset=valid_dataset \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.hidden_dropout_prob = 0.3\n",
    "model.config.attention_probs_dropout_prob = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to MPS\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_predictions(model, tokenizer, texts):\n",
    "    model.eval()\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits.to(\"cpu\").numpy()\n",
    "    probs = torch.sigmoid(torch.tensor(logits))  # Convert logits to probabilities\n",
    "    preds = (probs > 0.5).int().numpy()  # Threshold at 0.5\n",
    "    \n",
    "    print(\"Raw Logits:\", logits)\n",
    "    print(\"Probabilities:\", probs.numpy())\n",
    "    print(\"Binary Predictions:\", preds)\n",
    "\n",
    "    return preds\n",
    "\n",
    "# Run Debugging\n",
    "example_texts = [\"Chief Information Officer\", \"VP of Engineering\"]\n",
    "debug_predictions(model, tokenizer, example_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, precision_score, recall_score, hamming_loss, jaccard_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(predictions, true_labels):\n",
    "    \"\"\"\n",
    "    Compute evaluation metrics for multi-label classification.\n",
    "    \"\"\"\n",
    "    # Convert logits to probabilities\n",
    "    probs = torch.sigmoid(torch.tensor(predictions))\n",
    "    \n",
    "    # Convert probabilities to binary labels (threshold=0.5)\n",
    "    preds = (probs > 0.5).int().numpy()\n",
    "    true_labels = np.array(true_labels)  # Ensure true labels are numpy array\n",
    "\n",
    "    # Compute metrics\n",
    "    metrics = {\n",
    "        \"Accuracy (Subset)\": accuracy_score(true_labels, preds),  # Subset accuracy (exact match)\n",
    "        \"Log Loss\": log_loss(true_labels, probs.numpy()),  # Log loss (lower is better)\n",
    "        \"F1 Score (Macro)\": f1_score(true_labels, preds, average=\"macro\"),  # F1-score across all labels\n",
    "        \"F1 Score (Micro)\": f1_score(true_labels, preds, average=\"micro\"),\n",
    "        \"Precision (Macro)\": precision_score(true_labels, preds, average=\"macro\"),\n",
    "        \"Recall (Macro)\": recall_score(true_labels, preds, average=\"macro\"),\n",
    "        \"Hamming Loss\": hamming_loss(true_labels, preds),  # Penalizes incorrect labels\n",
    "        \"Jaccard Score (Macro)\": jaccard_score(true_labels, preds, average=\"macro\")\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_titles = [\"devops team leader\", \"human resources director & business partner\"]\n",
    "\n",
    "# Filter DataFrame to get the real labels\n",
    "real_labels = data_frame[data_frame[\"Title\"].isin(example_titles)][[\"Title\", \"Features\"]]\n",
    "\n",
    "# Print real labels\n",
    "print(real_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(model, tokenizer, texts, true_labels):\n",
    "    \"\"\"\n",
    "    Perform predictions and compute evaluation metrics.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Tokenize inputs\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Make predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits.to(\"cpu\").numpy()  # Move logits to CPU for processing\n",
    "    metrics = compute_metrics(logits, true_labels)  # Compute evaluation metrics\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Example Usage\n",
    "example_texts = [\"devops team leader\", \"human resources director & business partner\"]\n",
    "true_labels = [[1, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0]]  # Replace with real labels\n",
    "\n",
    "metrics = predict_and_evaluate(model, tokenizer, example_texts, true_labels)\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
